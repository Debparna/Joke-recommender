{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation \n",
    "\n",
    "\n",
    "## The MovieLens Dataset\n",
    "Contains 1,000,209 anonymous ratings of approximately 3,900 movies made by 6,040 MovieLens users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'dat/ratings.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-91a44cf058a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                     \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                     names=['user_id', 'movie_id', 'rating', 'timestamp'])\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Set max_userid to the maximum user_id in the ratings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deb/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deb/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deb/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deb/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1057\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[1;32m   1058\u001b[0m                                      engine=engine))\n\u001b[0;32m-> 1059\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deb/anaconda2/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2072\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[1;32m   2073\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2074\u001b[0;31m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[1;32m   2075\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/deb/anaconda2/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# Python 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'dat/ratings.dat'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define file directories\n",
    "MOVIELENS_DIR = 'dat'\n",
    "USER_DATA_FILE = 'users.dat'\n",
    "MOVIE_DATA_FILE = 'movies.dat'\n",
    "RATING_DATA_FILE = 'ratings.dat'\n",
    "\n",
    "# Specify User's Age and Occupation Column\n",
    "AGES = { 1: \"Under 18\", 18: \"18-24\", 25: \"25-34\", 35: \"35-44\", 45: \"45-49\", 50: \"50-55\", 56: \"56+\" }\n",
    "OCCUPATIONS = { 0: \"other or not specified\", 1: \"academic/educator\", 2: \"artist\", 3: \"clerical/admin\",\n",
    "                4: \"college/grad student\", 5: \"customer service\", 6: \"doctor/health care\",\n",
    "                7: \"executive/managerial\", 8: \"farmer\", 9: \"homemaker\", 10: \"K-12 student\", 11: \"lawyer\",\n",
    "                12: \"programmer\", 13: \"retired\", 14: \"sales/marketing\", 15: \"scientist\", 16: \"self-employed\",\n",
    "                17: \"technician/engineer\", 18: \"tradesman/craftsman\", 19: \"unemployed\", 20: \"writer\" }\n",
    "\n",
    "# Define csv files to be saved into\n",
    "USERS_CSV_FILE = 'users.csv'\n",
    "MOVIES_CSV_FILE = 'movies.csv'\n",
    "RATINGS_CSV_FILE = 'ratings.csv'\n",
    "\n",
    "# Read the Ratings File\n",
    "ratings = pd.read_csv(os.path.join(MOVIELENS_DIR, RATING_DATA_FILE), \n",
    "                    sep='::', \n",
    "                    engine='python', \n",
    "                    encoding='latin-1',\n",
    "                    names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
    "\n",
    "# Set max_userid to the maximum user_id in the ratings\n",
    "max_userid = ratings['user_id'].drop_duplicates().max()\n",
    "# Set max_movieid to the maximum movie_id in the ratings\n",
    "max_movieid = ratings['movie_id'].drop_duplicates().max()\n",
    "\n",
    "# Process ratings dataframe for Keras Deep Learning model\n",
    "# Add user_emb_id column whose values == user_id - 1\n",
    "ratings['user_emb_id'] = ratings['user_id'] - 1\n",
    "# Add movie_emb_id column whose values == movie_id - 1\n",
    "ratings['movie_emb_id'] = ratings['movie_id'] - 1\n",
    "\n",
    "print len(ratings), 'ratings loaded'\n",
    "\n",
    "# Save into ratings.csv\n",
    "ratings.to_csv(RATINGS_CSV_FILE, \n",
    "               sep='\\t', \n",
    "               header=True, \n",
    "               encoding='latin-1', \n",
    "               columns=['user_id', 'movie_id', 'rating', 'timestamp', 'user_emb_id', 'movie_emb_id'])\n",
    "print 'Saved to', RATINGS_CSV_FILE\n",
    "\n",
    "# Read the Users File\n",
    "users = pd.read_csv(os.path.join(MOVIELENS_DIR, USER_DATA_FILE), \n",
    "                    sep='::', \n",
    "                    engine='python', \n",
    "                    encoding='latin-1',\n",
    "                    names=['user_id', 'gender', 'age', 'occupation', 'zipcode'])\n",
    "users['age_desc'] = users['age'].apply(lambda x: AGES[x])\n",
    "users['occ_desc'] = users['occupation'].apply(lambda x: OCCUPATIONS[x])\n",
    "print len(users), 'descriptions of', max_userid, 'users loaded.'\n",
    "\n",
    "# Save into users.csv\n",
    "users.to_csv(USERS_CSV_FILE, \n",
    "             sep='\\t', \n",
    "             header=True, \n",
    "             encoding='latin-1',\n",
    "             columns=['user_id', 'gender', 'age', 'occupation', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "print 'Saved to', USERS_CSV_FILE\n",
    "\n",
    "# Read the Movies File\n",
    "movies = pd.read_csv(os.path.join(MOVIELENS_DIR, MOVIE_DATA_FILE), \n",
    "                    sep='::', \n",
    "                    engine='python', \n",
    "                    encoding='latin-1',\n",
    "                    names=['movie_id', 'title', 'genres'])\n",
    "print len(movies), 'descriptions of', max_movieid, 'movies loaded.'\n",
    "\n",
    "# Save into movies.csv\n",
    "movies.to_csv(MOVIES_CSV_FILE, \n",
    "              sep='\\t', \n",
    "              header=True, \n",
    "              columns=['movie_id', 'title', 'genres'])\n",
    "print 'Saved to', MOVIES_CSV_FILE\n",
    "\n",
    "# Reading ratings file\n",
    "# Ignore the timestamp column\n",
    "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Reading users file\n",
    "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'Drama', 1603],\n",
       " [u'Comedy', 1200],\n",
       " [u'Action', 503],\n",
       " [u'Thriller', 492],\n",
       " [u'Romance', 471]]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reading ratings file\n",
    "# Ignore the timestamp column\n",
    "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Reading users file\n",
    "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "\n",
    "# Reading movies file\n",
    "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])\n",
    "\n",
    "# Join all 3 files into one dataframe\n",
    "dataset = pd.merge(pd.merge(movies, ratings),users)\n",
    "# Display 20 movies with highest ratings\n",
    "dataset[['title','genres','rating']].sort_values('rating', ascending=False).head(20)\n",
    "\n",
    "# Make a census of the genre keywords\n",
    "genre_labels = set()\n",
    "for s in movies['genres'].str.split('|').values:\n",
    "    genre_labels = genre_labels.union(set(s))\n",
    "\n",
    "# Function that counts the number of times each of the genre keywords appear\n",
    "def count_word(dataset, ref_col, census):\n",
    "    keyword_count = dict()\n",
    "    for s in census: \n",
    "        keyword_count[s] = 0\n",
    "    for census_keywords in dataset[ref_col].str.split('|'):        \n",
    "        if type(census_keywords) == float and pd.isnull(census_keywords): \n",
    "            continue        \n",
    "        for s in [s for s in census_keywords if s in census]: \n",
    "            if pd.notnull(s): \n",
    "                keyword_count[s] += 1\n",
    "    #______________________________________________________________________\n",
    "    # convert the dictionary in a list to sort the keywords by frequency\n",
    "    keyword_occurences = []\n",
    "    for k,v in keyword_count.items():\n",
    "        keyword_occurences.append([k,v])\n",
    "    keyword_occurences.sort(key = lambda x:x[1], reverse = True)\n",
    "    return keyword_occurences, keyword_count\n",
    "\n",
    "# Calling this function gives access to a list of genre keywords which are sorted by decreasing frequency\n",
    "keyword_occurences, dum = count_word(movies, 'genres', genre_labels)\n",
    "keyword_occurences[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content based filtering\n",
    "A Content-Based Recommendation Engine that computes similarity between movies based on movie genres. It will suggest movies that are most similar to a particular movie based on its genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Break up the big genre string into a string array\n",
    "movies['genres'] = movies['genres'].str.split('|')\n",
    "# Convert genres to string value\n",
    "movies['genres'] = movies['genres'].fillna(\"\").astype('str')\n",
    "\n",
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(movies['genres'])\n",
    "tfidf_matrix.shape\n",
    "\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "cosine_sim[:4, :4]\n",
    "\n",
    "# Build a 1-dimensional array with movie titles\n",
    "titles = movies['title']\n",
    "indices = pd.Series(movies.index, index=movies['title'])\n",
    "\n",
    "# Function that get movie recommendations based on the cosine similarity score of movie genres\n",
    "def genre_recommendations(title):\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:21]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import cross_validation as cv\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# Fill NaN values in user_id and movie_id column with 0\n",
    "ratings['user_id'] = ratings['user_id'].fillna(0)\n",
    "ratings['movie_id'] = ratings['movie_id'].fillna(0)\n",
    "\n",
    "# Replace NaN values in rating column with average of all values\n",
    "ratings['rating'] = ratings['rating'].fillna(ratings['rating'].mean())\n",
    "\n",
    "# Randomly sample 1% of the ratings dataset\n",
    "small_data = ratings.sample(frac=0.02)\n",
    "\n",
    "train_data, test_data = cv.train_test_split(small_data, test_size=0.2)\n",
    "\n",
    "# Create two user-item matrices, one for training and another for testing\n",
    "train_data_matrix = train_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
    "test_data_matrix = test_data.as_matrix(columns = ['user_id', 'movie_id', 'rating'])\n",
    "\n",
    "# Check their shape\n",
    "#print(train_data_matrix.shape)\n",
    "#print(test_data_matrix.shape)\n",
    "\n",
    "# User Similarity Matrix\n",
    "user_correlation = 1 - pairwise_distances(train_data, metric='correlation')\n",
    "user_correlation[np.isnan(user_correlation)] = 0\n",
    "#print(user_correlation[:4, :4])\n",
    "\n",
    "# Item Similarity Matrix\n",
    "item_correlation = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')\n",
    "item_correlation[np.isnan(item_correlation)] = 0\n",
    "#print(item_correlation[:4, :4])\n",
    "\n",
    "# Function to predict ratings\n",
    "def predict(ratings, similarity, type='user'):\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        # Use np.newaxis so that mean_user_rating has same format as ratings\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-based CF RMSE: 1437.40854832\n",
      "Item-based CF RMSE: 1653.62539163\n",
      "User-based CF RMSE: 695.788776843\n",
      "Item-based CF RMSE: 177.359482908\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Function to calculate RMSE\n",
    "def rmse(pred, actual):\n",
    "    # Ignore nonzero terms.\n",
    "    pred = pred[actual.nonzero()].flatten()\n",
    "    actual = actual[actual.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(pred, actual))\n",
    "\n",
    "# Predict ratings on the training data with both similarity score\n",
    "user_prediction = predict(train_data_matrix, user_correlation, type='user')\n",
    "item_prediction = predict(train_data_matrix, item_correlation, type='item')\n",
    "\n",
    "# RMSE on the test data\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, test_data_matrix)))\n",
    "\n",
    "# RMSE on the train data\n",
    "print('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
    "print('Item-based CF RMSE: ' + str(rmse(item_prediction, train_data_matrix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Model\n",
    "\n",
    "The basic idea is that the actual ratings of movies for each user can be represented by a matrix, say of users on the rows and movies along the columns.  We don’t have the full rating matrix, instead, we have a very sparse set of entries.  But if we could factor the rating matrix into two separate matrices, say one that was Users by Latent Factors, and one that was Latent Factors by Movies, then we could find the user’s rating for any movie by taking the dot product of the User row and the Movie column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deb/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: [3694 4433 1021 ... 4992 4646 4655] , shape = (1000209,)\n",
      "Movies: [3498 2301 1999 ...   57 1304 1233] , shape = (1000209,)\n",
      "Ratings: [3 4 3 ... 5 5 5] , shape = (1000209,)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from CFModel import CFModel\n",
    "\n",
    "\n",
    "ratings = pd.read_csv('ratings.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'movie_id', 'user_emb_id', 'movie_emb_id', 'rating'])\n",
    "max_userid = ratings['user_id'].drop_duplicates().max()\n",
    "max_movieid = ratings['movie_id'].drop_duplicates().max()\n",
    "\n",
    "users = pd.read_csv('users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "movies = pd.read_csv('movies.csv', sep='\\t', encoding='latin-1', usecols=['movie_id', 'title', 'genres'])\n",
    "\n",
    "# Create training set\n",
    "shuffled_ratings = ratings.sample(frac=1.)\n",
    "\n",
    "# Shuffling users\n",
    "Users = shuffled_ratings['user_emb_id'].values\n",
    "print 'Users:', Users, ', shape =', Users.shape\n",
    "\n",
    "# Shuffling movies\n",
    "Movies = shuffled_ratings['movie_emb_id'].values\n",
    "print 'Movies:', Movies, ', shape =', Movies.shape\n",
    "\n",
    "# Shuffling ratings\n",
    "Ratings = shuffled_ratings['rating'].values\n",
    "print 'Ratings:', Ratings, ', shape =', Ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CFModel.py:28: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  self.add(Merge([P, Q], mode='dot', dot_axes=1))\n",
      "/home/deb/anaconda2/lib/python2.7/site-packages/keras/models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900188 samples, validate on 100021 samples\n",
      "Epoch 1/30\n",
      " - 408s - loss: 8.1697 - val_loss: 2.2583\n",
      "Epoch 2/30\n",
      " - 412s - loss: 1.4808 - val_loss: 1.1373\n",
      "Epoch 3/30\n",
      " - 408s - loss: 1.0038 - val_loss: 0.9509\n",
      "Epoch 4/30\n",
      " - 396s - loss: 0.8945 - val_loss: 0.8856\n",
      "Epoch 5/30\n",
      " - 417s - loss: 0.8465 - val_loss: 0.8504\n",
      "Epoch 6/30\n",
      " - 424s - loss: 0.8148 - val_loss: 0.8259\n",
      "Epoch 7/30\n",
      " - 415s - loss: 0.7901 - val_loss: 0.8098\n",
      "Epoch 8/30\n",
      " - 416s - loss: 0.7694 - val_loss: 0.7970\n",
      "Epoch 9/30\n",
      " - 419s - loss: 0.7493 - val_loss: 0.7870\n",
      "Epoch 10/30\n",
      " - 422s - loss: 0.7297 - val_loss: 0.7760\n",
      "Epoch 11/30\n",
      " - 416s - loss: 0.7099 - val_loss: 0.7685\n",
      "Epoch 12/30\n",
      " - 432s - loss: 0.6895 - val_loss: 0.7616\n",
      "Epoch 13/30\n",
      " - 433s - loss: 0.6689 - val_loss: 0.7563\n",
      "Epoch 14/30\n",
      " - 432s - loss: 0.6483 - val_loss: 0.7498\n",
      "Epoch 15/30\n",
      " - 412s - loss: 0.6273 - val_loss: 0.7484\n",
      "Epoch 16/30\n",
      " - 405s - loss: 0.6062 - val_loss: 0.7468\n",
      "Epoch 17/30\n",
      " - 407s - loss: 0.5855 - val_loss: 0.7443\n",
      "Epoch 18/30\n",
      " - 415s - loss: 0.5645 - val_loss: 0.7485\n",
      "Epoch 19/30\n",
      " - 419s - loss: 0.5443 - val_loss: 0.7500\n",
      "Minimum RMSE at epoch 17 = 0.8627\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>prediction</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2905</td>\n",
       "      <td>5.104347</td>\n",
       "      <td>Sanjuro (1962)</td>\n",
       "      <td>Action|Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3092</td>\n",
       "      <td>5.015607</td>\n",
       "      <td>Chushingura (1962)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>669</td>\n",
       "      <td>4.999459</td>\n",
       "      <td>Aparajito (1956)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1423</td>\n",
       "      <td>4.953498</td>\n",
       "      <td>Hearts and Minds (1996)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3338</td>\n",
       "      <td>4.925403</td>\n",
       "      <td>For All Mankind (1989)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>668</td>\n",
       "      <td>4.920885</td>\n",
       "      <td>Pather Panchali (1955)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1111</td>\n",
       "      <td>4.878110</td>\n",
       "      <td>Microcosmos (Microcosmos: Le peuple de l'herbe...</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1949</td>\n",
       "      <td>4.873702</td>\n",
       "      <td>Man for All Seasons, A (1966)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>670</td>\n",
       "      <td>4.868108</td>\n",
       "      <td>World of Apu, The (Apur Sansar) (1959)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>745</td>\n",
       "      <td>4.862697</td>\n",
       "      <td>Close Shave, A (1995)</td>\n",
       "      <td>Animation|Comedy|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3134</td>\n",
       "      <td>4.859750</td>\n",
       "      <td>Grand Illusion (Grande illusion, La) (1937)</td>\n",
       "      <td>Drama|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3022</td>\n",
       "      <td>4.857942</td>\n",
       "      <td>General, The (1927)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>649</td>\n",
       "      <td>4.833371</td>\n",
       "      <td>Cold Fever (Á köldum klaka) (1994)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>116</td>\n",
       "      <td>4.832465</td>\n",
       "      <td>Anne Frank Remembered (1995)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>916</td>\n",
       "      <td>4.818557</td>\n",
       "      <td>Roman Holiday (1953)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019</td>\n",
       "      <td>4.807254</td>\n",
       "      <td>Seven Samurai (The Magnificent Seven) (Shichin...</td>\n",
       "      <td>Action|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2920</td>\n",
       "      <td>4.802969</td>\n",
       "      <td>Children of Paradise (Les enfants du paradis) ...</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>326</td>\n",
       "      <td>4.796769</td>\n",
       "      <td>To Live (Huozhe) (1994)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>954</td>\n",
       "      <td>4.791075</td>\n",
       "      <td>Mr. Smith Goes to Washington (1939)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>922</td>\n",
       "      <td>4.788300</td>\n",
       "      <td>Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)</td>\n",
       "      <td>Film-Noir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    movie_id  prediction                                              title  \\\n",
       "0       2905    5.104347                                     Sanjuro (1962)   \n",
       "1       3092    5.015607                                 Chushingura (1962)   \n",
       "2        669    4.999459                                   Aparajito (1956)   \n",
       "3       1423    4.953498                            Hearts and Minds (1996)   \n",
       "4       3338    4.925403                             For All Mankind (1989)   \n",
       "5        668    4.920885                             Pather Panchali (1955)   \n",
       "6       1111    4.878110  Microcosmos (Microcosmos: Le peuple de l'herbe...   \n",
       "7       1949    4.873702                      Man for All Seasons, A (1966)   \n",
       "8        670    4.868108             World of Apu, The (Apur Sansar) (1959)   \n",
       "9        745    4.862697                              Close Shave, A (1995)   \n",
       "10      3134    4.859750        Grand Illusion (Grande illusion, La) (1937)   \n",
       "11      3022    4.857942                                General, The (1927)   \n",
       "12       649    4.833371                 Cold Fever (Á köldum klaka) (1994)   \n",
       "13       116    4.832465                       Anne Frank Remembered (1995)   \n",
       "14       916    4.818557                               Roman Holiday (1953)   \n",
       "15      2019    4.807254  Seven Samurai (The Magnificent Seven) (Shichin...   \n",
       "16      2920    4.802969  Children of Paradise (Les enfants du paradis) ...   \n",
       "17       326    4.796769                            To Live (Huozhe) (1994)   \n",
       "18       954    4.791075                Mr. Smith Goes to Washington (1939)   \n",
       "19       922    4.788300      Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)   \n",
       "\n",
       "                       genres  \n",
       "0            Action|Adventure  \n",
       "1                       Drama  \n",
       "2                       Drama  \n",
       "3                       Drama  \n",
       "4                 Documentary  \n",
       "5                       Drama  \n",
       "6                 Documentary  \n",
       "7                       Drama  \n",
       "8                       Drama  \n",
       "9   Animation|Comedy|Thriller  \n",
       "10                  Drama|War  \n",
       "11                     Comedy  \n",
       "12               Comedy|Drama  \n",
       "13                Documentary  \n",
       "14             Comedy|Romance  \n",
       "15               Action|Drama  \n",
       "16              Drama|Romance  \n",
       "17                      Drama  \n",
       "18                      Drama  \n",
       "19                  Film-Noir  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define constants\n",
    "K_FACTORS = 100 # The number of dimensional embeddings for movies and users\n",
    "TEST_USER = 2000 # A random test user (user_id = 2000)\n",
    "\n",
    "# Define model\n",
    "model = CFModel(max_userid, max_movieid, K_FACTORS)\n",
    "# Compile the model using MSE as the loss function and the AdaMax learning algorithm\n",
    "model.compile(loss='mse', optimizer='adamax')\n",
    "\n",
    "# Callbacks monitor the validation loss\n",
    "# Save the model weights each time the validation loss has improved\n",
    "callbacks = [EarlyStopping('val_loss', patience=2), \n",
    "             ModelCheckpoint('weights.h5', save_best_only=True)]\n",
    "\n",
    "# Use 30 epochs, 90% training data, 10% validation data \n",
    "history = model.fit([Users, Movies], Ratings, nb_epoch=30, validation_split=.1, verbose=2, callbacks=callbacks)\n",
    "\n",
    "# Show the best validation RMSE\n",
    "min_val_loss, idx = min((val, idx) for (idx, val) in enumerate(history.history['val_loss']))\n",
    "print 'Minimum RMSE at epoch', '{:d}'.format(idx+1), '=', '{:.4f}'.format(math.sqrt(min_val_loss))\n",
    "\n",
    "# Use the pre-trained model\n",
    "trained_model = CFModel(max_userid, max_movieid, K_FACTORS)\n",
    "# Load weights\n",
    "trained_model.load_weights('weights.h5')\n",
    "\n",
    "# Pick a random test user\n",
    "users[users['user_id'] == TEST_USER]\n",
    "\n",
    "# Function to predict the ratings given User ID and Movie ID\n",
    "def predict_rating(user_id, movie_id):\n",
    "    return trained_model.rate(user_id - 1, movie_id - 1)\n",
    "\n",
    "user_ratings = ratings[ratings['user_id'] == TEST_USER][['user_id', 'movie_id', 'rating']]\n",
    "user_ratings['prediction'] = user_ratings.apply(lambda x: predict_rating(TEST_USER, x['movie_id']), axis=1)\n",
    "user_ratings.sort_values(by='rating', \n",
    "                         ascending=False).merge(movies, \n",
    "                                                on='movie_id', \n",
    "                                                how='inner', \n",
    "                                                suffixes=['_u', '_m']).head(20)\n",
    "\n",
    "recommendations = ratings[ratings['movie_id'].isin(user_ratings['movie_id']) == False][['movie_id']].drop_duplicates()\n",
    "recommendations['prediction'] = recommendations.apply(lambda x: predict_rating(TEST_USER, x['movie_id']), axis=1)\n",
    "recommendations.sort_values(by='prediction',\n",
    "                          ascending=False).merge(movies,\n",
    "                                                 on='movie_id',\n",
    "                                                 how='inner',\n",
    "                                                 suffixes=['_u', '_m']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
